{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YogiJungHoonYeon/Artificial-Intelligence-Lang/blob/main/Tacotron2_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiSH43LOJ7EM"
      },
      "source": [
        "#!pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyZPPWJ8J8ZC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "803811a3-ca91-4368-f806-9ecf64a5dcdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6082 sha256=ddb051b9470f71804da12404f60c8123a06a1db1ef0f0bc9d0c85e292fe22d7b\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg\n",
            "Successfully installed ffmpeg-1.4\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Collecting jamo\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: jamo\n",
            "Successfully installed jamo-0.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install ffmpeg\n",
        "!pip install pydub\n",
        "!pip install jamo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkji2aYQJye9"
      },
      "source": [
        "#modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qefaQTnJ6CO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "import re\n",
        "import pandas as pd\n",
        "from jamo import h2j, j2hcj\n",
        "from scipy.io import wavfile #입력\n",
        "import IPython.display as ipd #출력\n",
        "from pydub import AudioSegment #m4a -> wave file\n",
        "import librosa\n",
        "import csv\n",
        "import unicodedata\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data_Preprocessing_New"
      ],
      "metadata": {
        "id": "dKj7JAAS5jGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9hsrn_6C5mBS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "507d8c74-6b8a-4ccd-ce3f-ea50baac18fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/MyDrive/wav_datasets/'\n",
        "csv_path = 'Data3.csv'\n",
        "def make_xlsx(dataset_path,csv_path):\n",
        "  file_name_list = []\n",
        "  for file_name in os.listdir(dataset_path):\n",
        "    file_name = file_name.replace('.wav','')\n",
        "    file_name_edit = unicodedata.normalize('NFC', file_name)\n",
        "    file_name_list.append(file_name_edit)\n",
        "  csv_data_frame_temp = pd.DataFrame(file_name_list,columns=['sentence'])\n",
        "  csv_data_frame_temp.to_csv(csv_path,index=False,encoding='utf-8-sig')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "make_xlsx(dataset_path,csv_path)\n"
      ],
      "metadata": {
        "id": "EHLWYYON542W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fqMQHrhzjZ5"
      },
      "source": [
        "#mkdir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xj2ZWM9i02_n"
      },
      "outputs": [],
      "source": [
        "os.mkdir('m4a_folder')\n",
        "os.mkdir('wav_folder')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8ZYzzqTOCu0"
      },
      "source": [
        "#word_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vatEW_mlOFih"
      },
      "outputs": [],
      "source": [
        "class ko_embedding():\n",
        "  def word_preprocessing(self,sentences):\n",
        "\n",
        "    stop_words = ['/', '\"', \"'\", '`', '@', '#', '$', '%', '^', '&', '*', '()', '(', ')', '_', '-', '+', '=', '<', '>']\n",
        "    vocab = []\n",
        "    filter = re.compile('[a-zA-Z0-9]')\n",
        "\n",
        "    for index, sentence in enumerate(sentences):\n",
        "      if index == 0:\n",
        "        print('첫번 째 sentence:{}'.format(sentence))\n",
        "      joined_sentence = '|'.join(sentence[0])\n",
        "\n",
        "\n",
        "      jamo_str = j2hcj(h2j(joined_sentence))\n",
        "\n",
        "      for stop_word in stop_words:\n",
        "        jamo_str = jamo_str.replace(stop_word,'')\n",
        "\n",
        "      jamo_str = list(jamo_str)\n",
        "\n",
        "      filter_list = filter.findall(sentence[0])\n",
        "      for filtered_word in filter_list:\n",
        "        jamo_str.remove(filtered_word)\n",
        "\n",
        "\n",
        "\n",
        "      vocab.append(jamo_str) #len(vocab) = number of words => [[문장1], [문장2], [문장3] ...]\n",
        "\n",
        "    return vocab\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def dict_make(self):\n",
        "    initial = ['ㄱ', 'ㄴ', 'ㄷ', 'ㄹ', 'ㅁ', 'ㅂ', 'ㅅ', 'ㅇ', 'ㅈ' ,'ㅊ','ㅋ', 'ㅌ','ㅍ','ㅎ','ㄲ','ㅃ','ㅉ','ㅆ','ㄸ'] #19\n",
        "    neutral = ['ㅏ','ㅐ','ㅑ','ㅒ','ㅓ','ㅔ','ㅕ','ㅖ','ㅗ','ㅘ','ㅙ','ㅚ','ㅛ','ㅜ','ㅝ','ㅞ','ㅟ','ㅠ','ㅡ','ㅢ','ㅣ'] #21\n",
        "    final = ['ㄱ','ㄲ','ㄳ','ㄴ','ㄵ','ㄶ','ㄷ','ㄹ','ㄺ','ㄻ','ㄼ','ㄽ','ㄾ','ㄿ','ㅀ','ㅁ','ㅂ','ㅄ','ㅅ','ㅆ','ㅇ','ㅈ','ㅊ','ㅋ','ㅌ','ㅍ','ㅎ',' '] #28\n",
        "\n",
        "    initial_dict = {}\n",
        "    neutral_dict = {}\n",
        "    final_dict = {}\n",
        "    added_dict = {}\n",
        "    for index, value in enumerate(initial):\n",
        "      initial_dict[value] = index\n",
        "    for index, value in enumerate(neutral):\n",
        "      neutral_dict[value] = index + len(initial)\n",
        "    for index, value in enumerate(final):\n",
        "      final_dict[value] = index + len(initial) + len(neutral)\n",
        "\n",
        "    added_dict['?'] = 71\n",
        "    added_dict['!'] = 72\n",
        "    added_dict['~'] = 73\n",
        "    added_dict['..'] = 74\n",
        "    added_dict['.'] = 75\n",
        "    added_dict[','] = 76\n",
        "    return initial_dict, neutral_dict, final_dict, added_dict\n",
        "\n",
        "  #[['ㅇ', 'ㅏ', 'ㄴ', '|', 'ㄴ', 'ㅕ', 'ㅇ', '|', ' ', '|', 'ㅇ', 'ㅣ', '|'\n",
        "  #, 'ㄹ', 'ㅏ', '|', 'ㄱ', 'ㅗ', '|', ' ', '|', 'ㅁ', 'ㅏ', 'ㄹ', '|', 'ㅎ', 'ㅐ', '|', 'ㄷ', 'ㅗ', '|', ' ', '|'\n",
        "  #, 'ㄷ', 'ㅙ', '|', 'ㅇ', 'ㅛ', '|', '?', '|', '!', '|', '~', '|', '!', '|', ' ', '|', '|', '|', '|', '|', '|']]\n",
        "  def word_embedding(self,vocab):\n",
        "    initial_dict,neutral_dict,final_dict,added_dict = self.dict_make()\n",
        "    encoded_vocab = []\n",
        "\n",
        "    for sentence in vocab:\n",
        "      i = 1\n",
        "      sentence_vocab = []\n",
        "      for character in sentence:\n",
        "\n",
        "        if character == '|' :\n",
        "          i = 1\n",
        "          continue;\n",
        "        if character == ' ':\n",
        "          i = 1\n",
        "          sentence_vocab.append(final_dict[character])\n",
        "          continue;\n",
        "        if character == '?' or character == '!' or character == '..' or character== '.' or character=='~' or character==',':\n",
        "          sentence_vocab.append(added_dict[character])\n",
        "          continue;\n",
        "\n",
        "        if i == 1:\n",
        "          sentence_vocab.append(initial_dict[character])\n",
        "        if i == 2:\n",
        "          sentence_vocab.append(neutral_dict[character])\n",
        "        if i == 3:\n",
        "          sentence_vocab.append(final_dict[character])\n",
        "        i  = i + 1\n",
        "        if i % 4 == 0:\n",
        "          i = 1\n",
        "\n",
        "      encoded_vocab.append(sentence_vocab)\n",
        "\n",
        "    return encoded_vocab\n",
        "\n",
        "\n",
        "\n",
        "  def final_word_embedding(self,encoded_vocab,embedding_dim):\n",
        "\n",
        "    length_list = []\n",
        "    vocab_list = []\n",
        "    for encoded_sentence in encoded_vocab:\n",
        "      encoded_sentence.insert(0, 68) #<sos>\n",
        "      encoded_sentence.append(69) #<eos>\n",
        "      length_list.append(len(encoded_sentence))\n",
        "    max_length = max(length_list)\n",
        "\n",
        "    for encoded_sentence in encoded_vocab:\n",
        "      for _ in range(max_length - len(encoded_sentence)):\n",
        "        encoded_sentence.append(70) #<pad>\n",
        "      vocab_list.append(encoded_sentence)\n",
        "\n",
        "    word_vec = np.zeros(shape=(len(encoded_vocab), max_length, embedding_dim))\n",
        "\n",
        "    for k, encoded_sentence in enumerate(vocab_list):\n",
        "\n",
        "      for m, i in enumerate(encoded_sentence):\n",
        "\n",
        "        word_vec[k,m,i] = 1\n",
        "\n",
        "    return word_vec\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def call(self,sentence_list):\n",
        "    vocab = self.word_preprocessing(sentence_list)\n",
        "\n",
        "    vocab = self.word_embedding(vocab)\n",
        "    word_vec = self.final_word_embedding(vocab,128)\n",
        "    word_vec = np.asarray(word_vec)\n",
        "    return word_vec\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktQO6y09OQYz"
      },
      "source": [
        "#mel-spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzM872X-OR5j"
      },
      "outputs": [],
      "source": [
        "def m4a_to_wav(m4a_folder_name, wav_folder_name):\n",
        "  dir_path = os.getcwd()\n",
        "\n",
        "  m4a_folder_path = os.path.join(dir_path, m4a_folder_name)\n",
        "  wav_folder_path = os.path.join(dir_path, wav_folder_name)\n",
        "\n",
        "  for file_name in os.listdir(m4a_folder_path):\n",
        "    file_path = os.path.join(m4a_folder_path, file_name)\n",
        "    if os.path.isdir(file_path) != True:\n",
        "      audio_m4a = AudioSegment.from_file(file_path, format='m4a')\n",
        "\n",
        "      wav_file_path = os.path.join(wav_folder_name, file_name)\n",
        "      audio_m4a.export(wav_file_path, format='wav')\n",
        "    else:\n",
        "      pass;\n",
        "\n",
        "\n",
        "def Mel_spectrogram(wav_folder_name, frame_length, frame_stride, n_mels):\n",
        "  mel_spectrogram_list = []\n",
        "  dir_name = os.getcwd()\n",
        "  wav_folder_path = os.path.join(dir_name, wav_folder_name)\n",
        "  for index, file_name in enumerate(os.listdir(wav_folder_path)):\n",
        "    if index ==0:\n",
        "      print('첫 번째 mel_spectrogram:{}'.format(file_name))\n",
        "    wav_file_path = os.path.join(wav_folder_path, file_name)\n",
        "    if os.path.isdir(wav_file_path) != True:\n",
        "      #print('wav_file_path in Mel_spctrogram def:{}'.format(wav_file_path))\n",
        "      data, sampling_rate = librosa.load(wav_file_path)\n",
        "      n_fft = int(round(sampling_rate * frame_length))\n",
        "      stride = int(round(sampling_rate * frame_stride))\n",
        "    else:\n",
        "      pass;\n",
        "\n",
        "    mel_spectrogram = librosa.feature.melspectrogram(y=data, sr=sampling_rate, n_fft=n_fft,\n",
        "                                                     hop_length = stride) #n_mels = n_channels\n",
        "    mel_spectrogram_list.append(mel_spectrogram)\n",
        "\n",
        "  return mel_spectrogram_list\n",
        "\n",
        "def mel_spectrogram_list_pad(Mel_spectrogram_list, embedding_dim):\n",
        "  length_list = []\n",
        "  for mel_spectrogram in Mel_spectrogram_list:\n",
        "    length_list.append(mel_spectrogram.shape[1])\n",
        "  max_length = max(length_list)\n",
        "  mel_spectrogram_list = []\n",
        "  for mel_spectrogram in Mel_spectrogram_list:\n",
        "    if max_length > embedding_dim:\n",
        "\n",
        "      mel_spectrogram = np.pad(mel_spectrogram, pad_width = ((0,0), (0,max_length - mel_spectrogram.shape[1])),\n",
        "            mode = 'constant', constant_values=0)\n",
        "      mel_spectrogram_list.append(mel_spectrogram)\n",
        "    else:\n",
        "      mel_spectrogram = np.pad(mel_spectrogram, pad_width = ((0,0), (0,embedding_dim - mel_spectrogram.shape[1])),\n",
        "            mode = 'constant', constant_values=0)\n",
        "      mel_spectrogram_list.append(mel_spectrogram)\n",
        "\n",
        "  return mel_spectrogram_list\n",
        "\n",
        "def mel_spectrogram_to_numpy(mel_spectrogram_list):\n",
        "  n_of_mel_spectrogram = len(mel_spectrogram_list)\n",
        "  mel_spectrogram_numpy = np.zeros((n_of_mel_spectrogram, mel_spectrogram_list[0].shape[0], mel_spectrogram_list[0].shape[1]))\n",
        "  for i, mel_spectrogram in enumerate(mel_spectrogram_list):\n",
        "    mel_spectrogram_numpy[i][:][:] = mel_spectrogram\n",
        "\n",
        "  return mel_spectrogram_numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMcK-yc4Oq22"
      },
      "outputs": [],
      "source": [
        "class audio_data_preprocessing():\n",
        "  def call(m4a_folder_name, wav_folder_name, frame_length, frame_stride, n_mels, embedding_dim):\n",
        "    #m4a_to_wav(m4a_folder_name, wav_folder_name)\n",
        "    mel_spectrogram_list = Mel_spectrogram(wav_folder_name, frame_length, frame_stride, n_mels)\n",
        "    mel_spectrogram_list = mel_spectrogram_list_pad(mel_spectrogram_list, embedding_dim)\n",
        "    mel_spectrogram = mel_spectrogram_to_numpy(mel_spectrogram_list)\n",
        "    return mel_spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riZrYSVN4GZs"
      },
      "outputs": [],
      "source": [
        "class audio_data_preprocessing_transformed():\n",
        "  def m4a_to_wav(self, m4a_folder_name, wav_folder_name):\n",
        "    dir_path = os.getcwd()\n",
        "    m4a_folder_path = os.path.join(dir_path, m4a_folder_name)\n",
        "    wav_folder_path = os.path.join(dir_path, wav_folder_name)\n",
        "\n",
        "    for file_name in os.listdir(m4a_folder_path):\n",
        "      file_path = os.path.join(m4a_folder_path, file_name)\n",
        "      if os.path.isdir(file_path) != True:\n",
        "        audio_m4a = AudioSegment.from_file(file_path, format='m4a')\n",
        "\n",
        "        wav_file_path = os.path.join(wav_folder_name, file_name)\n",
        "        audio_m4a.export(wav_file_path, format='wav')\n",
        "      else:\n",
        "        pass;\n",
        "  def Mel_spectrogram(self,wav_folder_name, frame_length, frame_stride, n_mels):\n",
        "    mel_spectrogram_list = []\n",
        "    dir_name = os.getcwd()\n",
        "    wav_folder_path = os.path.join(dir_name, wav_folder_name)\n",
        "    for file_name in os.listdir(wav_folder_path):\n",
        "      wav_file_path = os.path.join(wav_folder_path, file_name)\n",
        "      if os.path.isdir(wav_file_path) != True:\n",
        "        data, sampling_rate = librosa.load(wav_file_path)\n",
        "        n_fft = int(round(sampling_rate * frame_length))\n",
        "        stride = int(round(sampling_rate * frame_stride))\n",
        "      else:\n",
        "        pass;\n",
        "\n",
        "      mel_spectrogram = librosa.feature.melspectrogram(y=data, sr=sampling_rate, n_fft=n_fft,\n",
        "                                                      hop_length = stride,n_mels = n_mels ) #n_mels = n_channels\n",
        "      mel_spectrogram_list.append(mel_spectrogram)\n",
        "\n",
        "    return mel_spectrogram_list\n",
        "  def mel_spectrogram_list_pad(self,Mel_spectrogram_list, embedding_dim):\n",
        "    length_list = []\n",
        "    for mel_spectrogram in Mel_spectrogram_list:\n",
        "      length_list.append(mel_spectrogram.shape[1])\n",
        "    max_length = max(length_list)\n",
        "    mel_spectrogram_list = []\n",
        "    for mel_spectrogram in Mel_spectrogram_list:\n",
        "      if max_length > embedding_dim:\n",
        "\n",
        "        mel_spectrogram = np.pad(mel_spectrogram, pad_width = ((0,0), (0,max_length - mel_spectrogram.shape[1])),\n",
        "              mode = 'constant', constant_values=0)\n",
        "        mel_spectrogram_list.append(mel_spectrogram)\n",
        "      else:\n",
        "        mel_spectrogram = np.pad(mel_spectrogram, pad_width = ((0,0), (0,embedding_dim - mel_spectrogram.shape[1])),\n",
        "              mode = 'constant', constant_values=0)\n",
        "        mel_spectrogram_list.append(mel_spectrogram)\n",
        "\n",
        "    return mel_spectrogram_list\n",
        "  def mel_spectrogram_to_numpy(self,mel_spectrogram_list):\n",
        "    n_of_mel_spectrogram = len(mel_spectrogram_list)\n",
        "    mel_spectrogram_numpy = np.zeros((n_of_mel_spectrogram, mel_spectrogram_list[0].shape[0], mel_spectrogram_list[0].shape[1]))\n",
        "    for i, mel_spectrogram in enumerate(mel_spectrogram_list):\n",
        "      mel_spectrogram_numpy[i][:][:] = mel_spectrogram\n",
        "\n",
        "    return mel_spectrogram_numpy\n",
        "\n",
        "  def call(self,m4a_folder_name, wav_folder_name, frame_length, frame_stride, n_mels, embedding_dim):\n",
        "\n",
        "    self.m4a_to_wav(m4a_folder_name, wav_folder_name)\n",
        "    mel_spectrogram_list = self.Mel_spectrogram(wav_folder_name, frame_length, frame_stride, n_mels)\n",
        "    mel_spectrogram_list = self.mel_spectrogram_list_pad(mel_spectrogram_list, embedding_dim)\n",
        "    mel_spectrogram = self.mel_spectrogram_to_numpy(mel_spectrogram_list)\n",
        "    return mel_spectrogram\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiaMFD34Oza2"
      },
      "source": [
        "#Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18dqjInEOyp_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "749a5b38-b550-48d0-be0f-2fe55dc201ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫번 째 sentence:['추웠던겨울은가고']\n",
            "첫 번째 mel_spectrogram:추웠던겨울은가고.wav\n"
          ]
        }
      ],
      "source": [
        "class train_data_generation():\n",
        "  def call(m4a_folder_name, wav_folder_name, frame_length, frame_stride, n_mels,csv_file_name,embedding_dim):\n",
        "    ko = ko_embedding()\n",
        "    sentence_list = []\n",
        "    df = pd.read_csv(csv_file_name)\n",
        "    for i in range(df.size):\n",
        "      sentence_list.append([df['sentence'][i]])\n",
        "\n",
        "    word_vec = ko.call(sentence_list)\n",
        "    word_vec = tf.cast(word_vec, tf.dtypes.float32)\n",
        "    mel_spectrogram = audio_data_preprocessing.call(m4a_folder_name, wav_folder_name, frame_length, frame_stride, n_mels,\n",
        "                                                    embedding_dim)\n",
        "\n",
        "    return word_vec, mel_spectrogram\n",
        "\n",
        "\n",
        "word_vec, mel_spectrogram = train_data_generation.call('m4a_folder','/content/drive/MyDrive/wav_datasets/', 0.025, 0.010\n",
        "                                                       , 80, 'Data3.csv',454 )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('word_vec.shape:{}, mel_spectrogram.shape:{}'.format(word_vec.shape, mel_spectrogram.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgSzidWvDlit",
        "outputId": "882cc62d-3d8d-4d1f-af69-82e7aa63a3e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word_vec.shape:(103, 94, 128), mel_spectrogram.shape:(103, 128, 846)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bemSOkmvO_w1"
      },
      "source": [
        "# Model_modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLDI0OMTPBDZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.activations import tanh, softmax\n",
        "from tensorflow.random import uniform\n",
        "from tensorflow.keras.layers import Conv1D, BatchNormalization, Bidirectional, Dense, LSTM\n",
        "from tensorflow.keras.models import Model,model_from_json\n",
        "from tensorflow.keras.losses import MeanSquaredError, Loss\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BONnogRjPMpP"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXpt1pswzGmS",
        "outputId": "b8b9dfd9-4a71-403a-8377-7dc9e8eb7417"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mel_spectrogram:(103, 128, 846), word_vec:(103, 94, 128)\n"
          ]
        }
      ],
      "source": [
        "print('mel_spectrogram:{}, word_vec:{}'.format(mel_spectrogram.shape, word_vec.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvvk5tH7fC5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cf4b3aa-af4a-40f5-c5a4-e2cf0e58a7b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(96, 128, 94)\n"
          ]
        }
      ],
      "source": [
        "class Encoder(Model):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.conv1d_1 = Conv1D(filters=16, kernel_size=5, padding = 'same')\n",
        "        self.conv1d_2 = Conv1D(filters = 64, kernel_size=5, padding= 'same')\n",
        "        self.conv1d_3 = Conv1D(filters=32, kernel_size=5,padding='same')\n",
        "\n",
        "        self.batch_norm_1 = BatchNormalization()\n",
        "        self.batch_norm_2 = BatchNormalization()\n",
        "        self.batch_norm_3 = BatchNormalization()\n",
        "        self.bi_lstm = Bidirectional(LSTM(units=64, return_sequences=True))\n",
        "        #mel_spectrogram C//2 = E_L\n",
        "\n",
        "\n",
        "\n",
        "    def call(self, word_vec):\n",
        "\n",
        "        first = self.conv1d_1(word_vec)\n",
        "        first_batch = self.batch_norm_1(first)\n",
        "\n",
        "        second = self.conv1d_2(first_batch)\n",
        "        second_batch = self.batch_norm_2(second)\n",
        "\n",
        "        third = self.conv1d_3(second_batch)\n",
        "        third_batch = self.batch_norm_3(third)\n",
        "\n",
        "        hidden = self.bi_lstm(third)\n",
        "        return hidden\n",
        "\n",
        "\n",
        "class Attention(Model):\n",
        "  def __init__(self, attention_dim):\n",
        "    super(Attention, self).__init__()\n",
        "\n",
        "\n",
        "    self.linear_after_lstm = Dense(units = attention_dim)\n",
        "    self.linear_hidden = Dense(units = attention_dim)\n",
        "    self.linear_filter = Dense(units = attention_dim)\n",
        "    #self.linear_location_sensitive = Dense(units = attention_dim, activation = 'relu')\n",
        "    #self.conv1D = Conv1D(filters = attention_dim, kernel_size = 1)\n",
        "    self.v = Dense(units = 1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def call(self, time, hidden, after_lstm, attention_score):\n",
        "    if time==0:\n",
        "\n",
        "\n",
        "      value_e = self.v(tanh(self.linear_hidden(tf.transpose(hidden, perm=[0,2,1]))))\n",
        "\n",
        "      attention_score = tf.transpose(softmax(value_e), perm=[0,2,1])\n",
        "\n",
        "      return attention_score\n",
        "\n",
        "    else:\n",
        "\n",
        "      #after_filtered = self.conv1D(attention_score) #(B,T,C) 1,1,atten_dim\n",
        "\n",
        "      value_e = self.v(tanh(self.linear_filter(tf.transpose(attention_score,perm=[0,2,1]))\n",
        "      + self.linear_hidden(tf.transpose(hidden, perm=[0,2,1]))\n",
        "       + self.linear_filter(tf.transpose(attention_score,perm=[0,2,1]))))\n",
        "      attention_score_result = tf.transpose(softmax(value_e), perm=[0,2,1])\n",
        "\n",
        "      return attention_score_result\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Decoder(Model):\n",
        "  def __init__(self):\n",
        "    super(Decoder,self).__init__()\n",
        "    self.prenet_1 = Dense(units = 64)\n",
        "    self.prenet_2 = Dense(units = 128, activation = 'relu')\n",
        "    #D_L = mel_shape C\n",
        "    self.LSTM_1 = LSTM(units = 64 , return_sequences=True)\n",
        "    self.LSTM_2 = LSTM(units = 128, activation = 'tanh', return_sequences=True)\n",
        "  def prenet(self, previous_decoder):\n",
        "    output_1 = self.prenet_1(previous_decoder)\n",
        "    output_2 = self.prenet_2(output_1)\n",
        "    return output_2\n",
        "\n",
        "\n",
        "\n",
        "  def call(self,previous_decoder, hidden,attention_score):\n",
        "    context_vector = tf.multiply(attention_score, hidden)\n",
        "\n",
        "    after_prenet = self.prenet(previous_decoder)\n",
        "\n",
        "    lstm_input_1 = tf.concat([context_vector, tf.transpose(after_prenet, perm=[0,2,1])],axis = -1)\n",
        "\n",
        "    after_lstm_1 = self.LSTM_1(lstm_input_1)\n",
        "\n",
        "\n",
        "    lstm_input_2 = tf.concat([context_vector, after_lstm_1],axis = -1)\n",
        "    after_lstm_2 = self.LSTM_2(lstm_input_2)\n",
        "\n",
        "    return after_lstm_2\n",
        "\n",
        "\n",
        "class Tacotron2(Model):\n",
        "  def __init__(self, attention_dim, mel_spectrogram_shape, batch_size,training = True):\n",
        "    super(Tacotron2, self).__init__()\n",
        "\n",
        "\n",
        "    self.encoder = Encoder()\n",
        "    self.attention = Attention(attention_dim)\n",
        "    self.decoder = Decoder()\n",
        "\n",
        "    self.stop_dense = Dense(units = 1, activation = 'sigmoid')\n",
        "    self.mel_spectrogram_dense = Dense(units = 1)\n",
        "\n",
        "    self.conv1D_1 = Conv1D(filters = 16, kernel_size = 31,  padding ='same')\n",
        "    self.conv1D_2 = Conv1D(filters = 32, kernel_size = 31,  padding ='same')\n",
        "    self.conv1D_3 = Conv1D(filters = 64, kernel_size = 31,  padding ='same')\n",
        "    self.conv1D_4 = Conv1D(filters = 128, kernel_size = 31,  padding ='same')\n",
        "\n",
        "\n",
        "\n",
        "    self.mel_shape = mel_spectrogram_shape\n",
        "    self.training = training\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  def post_net(self, predicted_mel_spectrogram):\n",
        "    conv_1 = self.conv1D_1(predicted_mel_spectrogram)\n",
        "    conv_2 = self.conv1D_2(conv_1)\n",
        "    conv_3 = self.conv1D_3(conv_2)\n",
        "    conv_4 = self.conv1D_4(conv_3)\n",
        "    return conv_4\n",
        "\n",
        "  @tf.function\n",
        "  def stop_cal(self,training , stop_threshold , stop_index, time,stop_prob):\n",
        "    if tf.equal(training, False) and tf.greater(stop_prob , stop_threshold) and tf.equal(stop_index, 0):\n",
        "      stop_index = time\n",
        "    return stop_index\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def call(self, inputs):\n",
        "    word_vec = inputs #B,T,C\n",
        "\n",
        "    hidden = self.encoder.call(word_vec)\n",
        "\n",
        "\n",
        "    attention_score_list = 0\n",
        "    after_lstm_list = 0\n",
        "    previous_decoder_list = []\n",
        "\n",
        "    stop_threshold = tf.constant(0.5, dtype = tf.float32)\n",
        "\n",
        "\n",
        "    stop_list = []\n",
        "    stop_index = 0\n",
        "\n",
        "    time_step = 0\n",
        "    load_value = self.mel_shape[1] // 100\n",
        "\n",
        "\n",
        "    mel_init = np.random.normal(size=[self.batch_size, self.mel_shape[2], 1])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for time in range(self.mel_shape[1]):\n",
        "\n",
        "      if time==0:\n",
        "\n",
        "        attention_score = self.attention.call(time, hidden, None, None)\n",
        "\n",
        "\n",
        "\n",
        "        after_lstm = self.decoder.call(mel_init, hidden, attention_score)\n",
        "\n",
        "\n",
        "      else:\n",
        "\n",
        "        attention_score = self.attention.call(time, hidden, after_lstm_list,attention_score_list)\n",
        "\n",
        "\n",
        "        after_lstm = self.decoder.call(previous_decoder_list[-1], hidden, attention_score)\n",
        "\n",
        "      predicted_mel_spectrogram_frame = self.mel_spectrogram_dense(tf.transpose(after_lstm,perm=[0,2,1]))\n",
        "\n",
        "      attention_score_list = attention_score\n",
        "      after_lstm_list = after_lstm\n",
        "\n",
        "\n",
        "\n",
        "      previous_decoder_list.append(predicted_mel_spectrogram_frame)\n",
        "\n",
        "      stop_prob_lstm = tf.expand_dims(tf.reduce_sum(tf.transpose(after_lstm,perm=[0,2,1]), axis = [0,1]), axis = 0)\n",
        "      stop_prob = self.stop_dense(stop_prob_lstm)\n",
        "\n",
        "      stop_list.append(stop_prob)\n",
        "\n",
        "      stop_index = self.stop_cal(self.training, stop_threshold, stop_index, time,stop_prob)\n",
        "\n",
        "      if time != 0:\n",
        "\n",
        "        if time % (load_value * 20) ==0:\n",
        "          print('=' * (time_step),'>', '-' * (100 - (time_step)))\n",
        "      if time_step < 101 and (time % load_value) == 0 :\n",
        "        time_step = time_step + 1\n",
        "\n",
        "\n",
        "\n",
        "    predicted_mel_spectrogram = tf.concat(previous_decoder_list, axis=-1)\n",
        "    if self.training == False:\n",
        "      predicted_mel_spectrogram = tf.where(tf.range(predicted_mel_spectrogram.shape[-1]) >= stop_index, 0, predicted_mel_spectrogram)\n",
        "\n",
        "    output = self.post_net(tf.transpose(predicted_mel_spectrogram, perm=[0,2,1]))\n",
        "\n",
        "    output = tf.transpose(output, perm = [0,2,1])\n",
        "\n",
        "    stop_train = tf.concat(stop_list,axis = -1) #(1,mel_temporal)\n",
        "\n",
        "\n",
        "    return output, stop_train\n",
        "\n",
        "\n",
        "\n",
        "def make_train_set(batch_size, mel_temporal, word_vec, mel_spectrogram):\n",
        "  batch_value = (word_vec.shape[0] // batch_size) * batch_size\n",
        "  word_vec_refine = word_vec[:batch_value,:,:]\n",
        "  mel_spectrogram_refine = mel_spectrogram[:batch_value,:,:]\n",
        "\n",
        "  word_vec_transpose = tf.transpose(word_vec_refine, perm=[0,2,1])\n",
        "  train_inputs = word_vec_transpose\n",
        "  stop_target = np.zeros(shape=(1, mel_temporal))\n",
        "  stop_target[0,-1] = 1\n",
        "  stop_target = np.tile(stop_target,[batch_value,1,1])\n",
        "\n",
        "  train_targets = (mel_spectrogram_refine,stop_target)\n",
        "\n",
        "  train_build = word_vec_transpose[:batch_size,:,:]\n",
        "  return train_inputs, train_targets,batch_size, mel_temporal,train_build\n",
        "train_inputs, train_targets, batch_size, mel_temporal,train_build = make_train_set(batch_size = 16, mel_temporal = mel_spectrogram.shape[-1], word_vec = word_vec,\n",
        "                                                                       mel_spectrogram = mel_spectrogram)\n",
        "\n",
        "tacotron2 = Tacotron2(attention_dim = 64, mel_spectrogram_shape = (batch_size,mel_temporal,128),batch_size = batch_size)\n",
        "\n",
        "learning_rate = 1e-3\n",
        "optimizer = Adam(learning_rate = learning_rate)\n",
        "tacotron2.compile(optimizer = optimizer,loss=MeanSquaredError(), metrics=['mse'])\n",
        "print(train_inputs.shape)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('build 시작')\n",
        "_ = tacotron2(train_build)"
      ],
      "metadata": {
        "id": "yMptspTM_fzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Training and Save (August 1st)\n",
        "\n"
      ],
      "metadata": {
        "id": "qmhRLd7RESkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "tacotron2.fit(train_inputs, train_targets, epochs=1, batch_size=batch_size, verbose=1, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFnCCeY6ERf2",
        "outputId": "bfd6b439-a60c-4a0f-d2ad-f1e16ed6d367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== > --------------------------------------------------------------------------------\n",
            "======================================== > ------------------------------------------------------------\n",
            "============================================================ > ----------------------------------------\n",
            "================================================================================ > --------------------\n",
            "==================================================================================================== > \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tacotron2_7/batch_normalization_23/gamma:0', 'tacotron2_7/batch_normalization_23/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tacotron2_7/batch_normalization_23/gamma:0', 'tacotron2_7/batch_normalization_23/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== > --------------------------------------------------------------------------------\n",
            "======================================== > ------------------------------------------------------------\n",
            "============================================================ > ----------------------------------------\n",
            "================================================================================ > --------------------\n",
            "==================================================================================================== > \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tacotron2_7/batch_normalization_23/gamma:0', 'tacotron2_7/batch_normalization_23/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tacotron2_7/batch_normalization_23/gamma:0', 'tacotron2_7/batch_normalization_23/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 2315s 7s/step - loss: 1.0703 - output_1_loss: 0.0716 - output_2_loss: 0.9987 - output_1_mse: 0.0716 - output_2_mse: 0.9987\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c178ca62200>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_json = tacotron2.to_json()\n",
        "with open('tacotron2_model.json', 'w') as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "metadata": {
        "id": "DEY2TvVRBaod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치를 저장\n",
        "tacotron2.save_weights('tacotron2_model_weights.h5')"
      ],
      "metadata": {
        "id": "YvO-dMQSBfVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Training and Save (August 2nd)"
      ],
      "metadata": {
        "id": "6z9-omgr-NqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 아키텍처를 로드할 때 사용자 정의 클래스 등록\n",
        "with open('/content/drive/MyDrive/tacotron2_model_save/tacotron2_model.json', 'r') as json_file:\n",
        "    model_json = json_file.read()\n",
        "\n",
        "#custom_objects 매개변수에 Tacotron2 클래스 등록\n",
        "tacotron3 = model_from_json(model_json, custom_objects={'Tacotron2': Tacotron2,\n",
        "                                                   'Encoder':Encoder, 'Decoder':Decoder, 'Attention':Attention})\n",
        "\n",
        "#Tacotron2 class 가 이전에 정의되어야 함"
      ],
      "metadata": {
        "id": "AOo1t2ZZ-U8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치를 로드\n",
        "_ = tacotron3(train_build)\n",
        "tacotron3.load_weights('/content/drive/MyDrive/tacotron2_model_save/tacotron2_model_weights.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ves3hlT-Y3B",
        "outputId": "41275b27-4931-4194-fd22-3d7992fd50fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== > --------------------------------------------------------------------------------\n",
            "======================================== > ------------------------------------------------------------\n",
            "============================================================ > ----------------------------------------\n",
            "================================================================================ > --------------------\n",
            "==================================================================================================== > \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "optimizer = Adam(learning_rate = learning_rate)\n",
        "tacotron3.compile(optimizer = optimizer,loss=MeanSquaredError(), metrics=['mse'])"
      ],
      "metadata": {
        "id": "FGnYJi-GAR9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tacotron3.fit(train_inputs, train_targets, epochs=1, batch_size=batch_size, verbose=1, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gb4VAGSd-Sjm",
        "outputId": "a9af228c-2dc0-4a5b-bd79-626a07c0a98f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== > --------------------------------------------------------------------------------\n",
            "======================================== > ------------------------------------------------------------\n",
            "============================================================ > ----------------------------------------\n",
            "================================================================================ > --------------------\n",
            "==================================================================================================== > \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tacotron2_1/batch_normalization_5/gamma:0', 'tacotron2_1/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tacotron2_1/batch_normalization_5/gamma:0', 'tacotron2_1/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== > --------------------------------------------------------------------------------\n",
            "======================================== > ------------------------------------------------------------\n",
            "============================================================ > ----------------------------------------\n",
            "================================================================================ > --------------------\n",
            "==================================================================================================== > \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tacotron2_1/batch_normalization_5/gamma:0', 'tacotron2_1/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tacotron2_1/batch_normalization_5/gamma:0', 'tacotron2_1/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 2382s 7s/step - loss: 0.0834 - output_1_loss: 0.0784 - output_2_loss: 0.0051 - output_1_mse: 0.0784 - output_2_mse: 0.0051\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7a32078e87c0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_json = tacotron3.to_json()\n",
        "with open('tacotron2_model.json', 'w') as json_file:\n",
        "    json_file.write(model_json)\n"
      ],
      "metadata": {
        "id": "02danhGdBo48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치를 저장\n",
        "tacotron3.save_weights('tacotron2_model_weights.h5')"
      ],
      "metadata": {
        "id": "_UE0JjLdBoxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "#os.mkdir('tacotron2_model_save_2')\n",
        "shutil.copy('tacotron2_model.json', 'tacotron2_model_save_2/')\n",
        "shutil.copy('tacotron2_model_weights.h5', 'tacotron2_model_save_2/')\n",
        "\n",
        "shutil.copytree('tacotron2_model_save_2/', '/content/drive/MyDrive/tacotron2_model_save_2/')\n",
        "# 현재 작업 디렉토리에 있는 Tacotron2 폴더를 구글 드라이브로 복사\n",
        "#shutil.copytree('tacotron2_model', '/content/drive/MyDrive/tacotron2_model2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tlgSFUQYBn2a",
        "outputId": "3ffb3912-064f-474c-b4b3-6b1814fe9a1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/tacotron2_model_save_2/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Training and Save(August 2nd -2)"
      ],
      "metadata": {
        "id": "DHh68Xr-KivZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/tacotron2_model_save_2/tacotron2_model.json', 'r') as json_file:\n",
        "    model_json = json_file.read()"
      ],
      "metadata": {
        "id": "9xk5lVThKh41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tacotron3 = model_from_json(model_json, custom_objects={'Tacotron2': Tacotron2,\n",
        "                                                   'Encoder':Encoder, 'Decoder':Decoder, 'Attention':Attention})\n",
        "_ = tacotron3(train_build)\n",
        "tacotron3.load_weights('/content/drive/MyDrive/tacotron2_model_save_2/tacotron2_model_weights.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P1N9SfLLQ-J",
        "outputId": "2b35e410-3670-4599-fa79-a5febd3f743d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Tacotron2.stop_cal at 0x7ff595e204c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Tacotron2.stop_cal at 0x7ff595e204c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== > --------------------------------------------------------------------------------\n",
            "======================================== > ------------------------------------------------------------\n",
            "============================================================ > ----------------------------------------\n",
            "================================================================================ > --------------------\n",
            "==================================================================================================== > \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "optimizer = Adam(learning_rate = learning_rate)\n",
        "tacotron3.compile(optimizer = optimizer,loss=MeanSquaredError(), metrics=['mse'])"
      ],
      "metadata": {
        "id": "Ry9LTN9TLZZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tacotron3.fit(train_inputs, train_targets, epochs=1, batch_size=batch_size, verbose=1, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjlByhFXLdC8",
        "outputId": "cb4e1a80-ceec-4a5c-dbf9-ca31da377467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== > --------------------------------------------------------------------------------\n",
            "======================================== > ------------------------------------------------------------\n",
            "============================================================ > ----------------------------------------\n",
            "================================================================================ > --------------------\n",
            "==================================================================================================== > \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tacotron2_1/batch_normalization_5/gamma:0', 'tacotron2_1/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tacotron2_1/batch_normalization_5/gamma:0', 'tacotron2_1/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== > --------------------------------------------------------------------------------\n",
            "======================================== > ------------------------------------------------------------\n",
            "============================================================ > ----------------------------------------\n",
            "================================================================================ > --------------------\n",
            "==================================================================================================== > \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tacotron2_1/batch_normalization_5/gamma:0', 'tacotron2_1/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tacotron2_1/batch_normalization_5/gamma:0', 'tacotron2_1/batch_normalization_5/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 2387s 7s/step - loss: 0.0733 - output_1_loss: 0.0721 - output_2_loss: 0.0012 - output_1_mse: 0.0721 - output_2_mse: 0.0012\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff4935cbcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_json = tacotron3.to_json()\n",
        "with open('tacotron2_model.json', 'w') as json_file:\n",
        "    json_file.write(model_json)\n"
      ],
      "metadata": {
        "id": "ZO3ZP1z_VKAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tacotron3.save_weights('tacotron2_model_weights.h5')"
      ],
      "metadata": {
        "id": "QYcbod8dVQ5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Training"
      ],
      "metadata": {
        "id": "OkRkAsmSwRb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_save_and_move(model_name,architecture_name,weights_name,save_folder_name,google_drive_save):\n",
        "  model_json = model_name.to_json()\n",
        "  with open(architecture_name, 'w') as json_file:\n",
        "    json_file.write(model_json)\n",
        "  model_name.save_weights(weights_name)\n",
        "  os.mkdir(save_folder_name)\n",
        "  shutil.copy(architecture_name, save_folder_name)\n",
        "  shutil.copy(weights_name, save_folder_name)\n",
        "  shutil.copytree(save_folder_name, google_drive_save)"
      ],
      "metadata": {
        "id": "1BA4WZI5C91i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_json = tacotron2.to_json()\n",
        "with open('tacotron2_model.json', 'w') as json_file:\n",
        "    json_file.write(model_json)\n"
      ],
      "metadata": {
        "id": "sdFufXYdWcdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치를 저장\n",
        "tacotron2.save_weights('tacotron2_model_weights.h5')"
      ],
      "metadata": {
        "id": "GT3iyGBMWluc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 아키텍처를 로드할 때 사용자 정의 클래스 등록\n",
        "with open('tacotron2_model.json', 'r') as json_file:\n",
        "    model_json = json_file.read()\n",
        "\n",
        "# custom_objects 매개변수에 Tacotron2 클래스 등록\n",
        "tacotron3 = model_from_json(model_json, custom_objects={'Tacotron2': Tacotron2,\n",
        "                                                        'Encoder':Encoder, 'Decoder':Decoder, 'Attention':Attention})\n"
      ],
      "metadata": {
        "id": "MO6eU6tFWowX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치를 로드\n",
        "_ = tacotron3(train_build)\n",
        "tacotron3.load_weights('tacotron2_model_weights.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWzgFomqWt8q",
        "outputId": "95d5fa6c-f12d-45f2-cdb7-c2d99c375c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Tacotron2.stop_cal at 0x77fa018d3490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Tacotron2.stop_cal at 0x77fa018d3490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== > --------------------------------------------------------------------------------\n",
            "======================================== > ------------------------------------------------------------\n",
            "============================================================ > ----------------------------------------\n",
            "================================================================================ > --------------------\n",
            "==================================================================================================== > \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# 현재 작업 디렉토리에 있는 Tacotron2 폴더를 구글 드라이브로 복사\n",
        "shutil.copytree('tacotron2_model', '/content/drive/MyDrive/tacotron2_model2')"
      ],
      "metadata": {
        "id": "B_5PIVdCX2ZR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d5bf4d5f-d219-4501-98bc-b4b43bb4fd90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/tacotron2_model2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyGEYZIOynH0"
      },
      "source": [
        "#Model_load and Predict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs = word_vec_transpose\n",
        "#stop_target = np.zeros(shape=(1, mel_temporal))\n",
        "#stop_target[0,-1] = 1\n",
        "#train_targets = (mel_spectrogram,stop_target)\n",
        "batch_size = 32\n",
        "tacotron2.compile(optimizer = optimizer,loss=MeanSquaredError(), metrics=['mse'])\n",
        "tacotron2.fit(train_inputs, train_targets, epochs=10, batch_size=batch_size, verbose=1, shuffle=True)"
      ],
      "metadata": {
        "id": "be4UTHCcRxui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33d1fc83-2a99-479b-f493-bb630e855b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "==================== > --------------------------------------------------------------------------------\n",
            "======================================== > ------------------------------------------------------------\n",
            "============================================================ > ----------------------------------------\n",
            "================================================================================ > --------------------\n",
            "==================================================================================================== > \n",
            "==================== > --------------------------------------------------------------------------------\n",
            "======================================== > ------------------------------------------------------------\n",
            "============================================================ > ----------------------------------------\n",
            "================================================================================ > --------------------\n",
            "==================================================================================================== > \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tacotron2.save('tacotron2_model',save_format='tf')\n",
        "print('save 끝 ')"
      ],
      "metadata": {
        "id": "yw4x0HfMwQ8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Li63eZY32T9s"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "#loaded_tacotron2 = load_model('tacotron2_model')\n",
        "\n",
        "loaded_model = load_model('/content/drive/MyDrive/tacotron2_model2', custom_objects={\n",
        "    'Encoder': 'Encoder',\n",
        "    'Attention': 'Attention',\n",
        "    'Decoder': 'Decoder',\n",
        "    'Tacotron2': 'Tacotron2'\n",
        "})\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath='check_point_tacotron2',  # 저장될 파일 경로와 이름 형식\n",
        "    save_freq=,  # 'epoch'로 설정하면 매 에포크마다 저장됩니다.\n",
        "    save_best_only=True,  # True로 설정하면 개선된 모델만 저장합니다.\n",
        "    monitor='손실_또는_평가_지표',  # 모니터링할 지표 설정\n",
        "    mode='auto',  # 'min', 'max', 또는 'auto'로 설정하여 지표가 최소화 또는 최대화되는지 결정\n",
        "    verbose=1  # 1로 설정하면 저장이 발생할 때마다 메시지가 출력됩니다.\n",
        ")"
      ],
      "metadata": {
        "id": "iOSodP1PjxVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFOwnNH6VllD"
      },
      "outputs": [],
      "source": [
        "loaded_tacotron2.training = False\n",
        "loaded_tacotron2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTv3dLXbbROE"
      },
      "outputs": [],
      "source": [
        "sentence_list = ['처음은안녕하세요']\n",
        "word_vec_predict = ko_embedding.call(sentence_list)\n",
        "word_vec_predict = tf.cast(word_vec_predict, tf.dtypes.float32)\n",
        "print(word_vec_predict.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGlrgs3AwJGe"
      },
      "outputs": [],
      "source": [
        "batch_size = 3\n",
        "word_vec_predict_batch = tf.tile(word_vec_predict, [batch_size, 1, 1])\n",
        "print(word_vec_predict_batch.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fC2NInZ2fuv5"
      },
      "outputs": [],
      "source": [
        "\n",
        "output, _ = loaded_tacotron2.predict(word_vec_predict_batch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8a47GlywS5_"
      },
      "outputs": [],
      "source": [
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yu1WXhx_0BwY"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "odel: \"tacotron2\"\n",
        "_________________________________________________________________\n",
        " Layer (type)                Output Shape              Param #\n",
        "=================================================================\n",
        " encoder (Encoder)           multiple                  596392\n",
        "\n",
        " attention (Attention)       multiple                  131713\n",
        "\n",
        " decoder (Decoder)           multiple                  3214080\n",
        "\n",
        " dense_6 (Dense)             multiple                  513\n",
        "\n",
        " dense_7 (Dense)             multiple                  513\n",
        "\n",
        " conv1d_4 (Conv1D)           multiple                  63504\n",
        "\n",
        " conv1d_5 (Conv1D)           multiple                  15904\n",
        "\n",
        " conv1d_6 (Conv1D)           multiple                  63552\n",
        "\n",
        " conv1d_7 (Conv1D)           multiple                  254080\n",
        "\n",
        " batch_normalization_3 (Batc  multiple                 0\n",
        " hNormalization)\n",
        "\n",
        "=================================================================\n",
        "Total params: 4,340,251\n",
        "Trainable params: 4,340,139\n",
        "Non-trainable params: 112\n",
        "____________________________\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tacotron2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUHzIzqhW8tX",
        "outputId": "9c913dfa-45d1-434c-e7d3-c5518eb74460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tacotron2_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_5 (Encoder)         multiple                  0 (unused)\n",
            "                                                                 \n",
            " attention_4 (Attention)     multiple                  0 (unused)\n",
            "                                                                 \n",
            " decoder_4 (Decoder)         multiple                  0 (unused)\n",
            "                                                                 \n",
            " dense_38 (Dense)            multiple                  129       \n",
            "                                                                 \n",
            " dense_39 (Dense)            multiple                  129       \n",
            "                                                                 \n",
            " conv1d_27 (Conv1D)          multiple                  127008    \n",
            "                                                                 \n",
            " conv1d_28 (Conv1D)          multiple                  63552     \n",
            "                                                                 \n",
            " conv1d_29 (Conv1D)          multiple                  254080    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 731,571\n",
            "Trainable params: 731,571\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Test Predict\n"
      ],
      "metadata": {
        "id": "C0x4G1hMVlOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ko = ko_embedding()\n",
        "word_vec_t = ko.call([['처음은 안녕하세요']])\n",
        "word_vec_transpose = tf.transpose(word_vec_t, perm=[0,2,1])\n",
        "#word_vec_transpose = tf.tile(word_vec_transpose, [batch_size,1,1 ])\n",
        "print(word_vec_transpose.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjHQmnBTVkBO",
        "outputId": "121e5a76-78b5-4ac9-a7db-30e3a7163136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫번 째 sentence:['처음은 안녕하세요']\n",
            "(16, 128, 23)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final = np.pad(word_vec_transpose, pad_width = ((0,0),(0,0), (0,71)),\n",
        "            mode = 'constant', constant_values=0)\n",
        "print(final.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVLTP5uyWTFM",
        "outputId": "68b32741-d4b8-4552-ce92-5a41230b0853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16, 128, 94)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/tacotron2_model_save_3/tacotron2_model.json', 'r') as json_file:\n",
        "    model_json = json_file.read()"
      ],
      "metadata": {
        "id": "yU4m2kGJacBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tacotron3 = model_from_json(model_json, custom_objects={'Tacotron2': Tacotron2,\n",
        "                                                   'Encoder':Encoder, 'Decoder':Decoder, 'Attention':Attention})\n",
        "_ = tacotron3(train_build)\n",
        "tacotron3.load_weights('/content/drive/MyDrive/tacotron2_model_save_3/tacotron2_model_weights.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snusJgw-ae-F",
        "outputId": "d5a05d0b-8c04-44a0-9116-dc2dbea384e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Tacotron2.stop_cal at 0x79471a11d1b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Tacotron2.stop_cal at 0x79471a11d1b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== > --------------------------------------------------------------------------------\n",
            "======================================== > ------------------------------------------------------------\n",
            "============================================================ > ----------------------------------------\n",
            "================================================================================ > --------------------\n",
            "==================================================================================================== > \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tacotron3.training = True"
      ],
      "metadata": {
        "id": "btosU7XoXBun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mel, stop = tacotron3.predict(final,batch_size = 16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaT_ReOZXFbs",
        "outputId": "47699464-1fca-49d5-f143-29c03bbb8296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================== > --------------------------------------------------------------------------------\n",
            "======================================== > ------------------------------------------------------------\n",
            "============================================================ > ----------------------------------------\n",
            "================================================================================ > --------------------\n",
            "==================================================================================================== > \n",
            "1/1 [==============================] - 670s 670s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mel[:1].shape)\n",
        "mel_test = mel[0]\n",
        "print(mel_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf1SGKZodntE",
        "outputId": "9e78f058-8585-45bb-ed3c-bf6d10b3d01e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 128, 846)\n",
            "(128, 846)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn4MSJdqyisY"
      },
      "source": [
        "#Audio File TransFormation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WLn2DmXwVug",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "70794fe2-ea1a-4f3a-f776-2ab0b9e3ca1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.QuadMesh at 0x794719dd2380>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "S_db = librosa.amplitude_to_db(np.abs(mel_test), ref=np.max)\n",
        "librosa.display.specshow(S_db)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otznhIu7xC7M"
      },
      "outputs": [],
      "source": [
        "import soundfile as sf\n",
        "inv_mel_spectrogram = librosa.feature.inverse.mel_to_audio(S_db)\n",
        "\n",
        "sf.write('stereo_file1.wav', inv_mel_spectrogram, 12000, 'PCM_24')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4beK9rQxQdU"
      },
      "outputs": [],
      "source": [
        "file_list = []\n",
        "for i in os.listdir('wav_folder'):\n",
        "  file_list.append(i)\n",
        "\n",
        "file_path = os.path.join('wav_folder', file_list[0])\n",
        "frequency, data = wavfile.read(file_path)\n",
        "ipd.Audio(data, rate=frequency)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U5mIWzNoeptB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "EiSH43LOJ7EM",
        "hkji2aYQJye9",
        "dKj7JAAS5jGP",
        "0fqMQHrhzjZ5",
        "n8ZYzzqTOCu0",
        "ktQO6y09OQYz",
        "qiaMFD34Oza2",
        "bemSOkmvO_w1",
        "BONnogRjPMpP",
        "qmhRLd7RESkZ",
        "6z9-omgr-NqO",
        "DHh68Xr-KivZ",
        "OkRkAsmSwRb5",
        "KyGEYZIOynH0",
        "C0x4G1hMVlOh",
        "cn4MSJdqyisY"
      ],
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMheQC9RFStqAjUBXIcqVrM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}